# src/pipelines/enhanced_universal_rag_pipeline.py
"""
Enhanced Universal RAG Pipeline with full LCEL integration
Includes: Image embedding, compliance, authoritative sources, and adaptive templates
"""

from langchain_core.runnables import (
    RunnableSequence, 
    RunnableLambda, 
    RunnablePassthrough,
    RunnableParallel,
    RunnableBranch
)
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_openai import ChatOpenAI
from langchain.retrievers import ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMChainExtractor
from typing import Dict, Any, List, Optional, Tuple
from enum import Enum
import asyncio
import logging
from datetime import datetime
from pydantic import BaseModel, Field
import re
import json

logger = logging.getLogger(__name__)

# ============= MODELS =============

class ContentCategory(Enum):
    """Content categories for compliance detection"""
    GAMBLING = "gambling"
    GENERAL = "general"
    FINANCE = "finance"
    HEALTH = "health"
    ADULT = "adult"

class EnhancedContent(BaseModel):
    """Enhanced content with images, sources, and compliance"""
    title: str
    content: str
    images: List[Dict[str, Any]] = Field(default_factory=list)
    sources: List[Dict[str, Any]] = Field(default_factory=list)
    compliance_notices: List[str] = Field(default_factory=list)
    metadata: Dict[str, Any] = Field(default_factory=dict)

class ContentAnalysis(BaseModel):
    """Content analysis results"""
    category: ContentCategory
    compliance_required: bool
    detected_keywords: List[str] = Field(default_factory=list)
    risk_level: str = "low"  # low, medium, high
    requires_age_verification: bool = False

# ============= ENHANCED PIPELINE =============

class EnhancedUniversalRAGPipeline:
    """Complete LCEL-based Universal RAG Pipeline with all enhancements"""
    
    def __init__(self, supabase_client, config: Dict[str, Any]):
        self.supabase = supabase_client
        self.config = config
        
        # Initialize components
        try:
            self.llm = ChatOpenAI(
                model=config.get("model", "gpt-4o-mini"),
                temperature=config.get("temperature", 0.7)
            )
        except Exception as e:
            # For testing or when API key is not available
            self.llm = None
        
        # Compliance keywords for auto-detection
        self.gambling_keywords = [
            "casino", "betting", "poker", "slots", "blackjack", "roulette",
            "gambling", "wager", "jackpot", "odds", "payout", "bonus",
            "free spins", "deposit", "withdrawal", "bet", "stake"
        ]
        
        self.compliance_notices = {
            "gambling": [
                "🔞 This content is intended for adults aged 18 and over.",
                "⚠️ Gambling can be addictive. Please play responsibly.",
                "📞 For gambling addiction support, contact: National Problem Gambling Helpline 1-800-522-4700",
                "🚫 Void where prohibited. Check local laws and regulations."
            ]
        }
        
    def create_pipeline(self) -> RunnableSequence:
        """Create the complete enhanced pipeline"""
        
        return RunnableSequence(
            # Step 1: Content Analysis - Auto-detect category and compliance needs
            RunnablePassthrough.assign(
                analysis=RunnableLambda(self._analyze_content)
            ),
            
            # Step 2: Parallel Resource Gathering - Images + Authoritative Sources
            RunnablePassthrough.assign(
                resources=RunnableParallel({
                    "images": RunnableLambda(self._gather_images),
                    "sources": RunnableLambda(self._gather_authoritative_sources)
                })
            ),
            
            # Step 3: Dynamic Template Enhancement
            RunnablePassthrough.assign(
                enhanced_template=RunnableLambda(self._enhance_template)
            ),
            
            # Step 4: Enhanced Retrieval with Context
            RunnablePassthrough.assign(
                retrieved_docs=RunnableLambda(self._enhanced_retrieval)
            ),
            
            # Step 5: Content Generation with Context
            RunnablePassthrough.assign(
                raw_content=RunnableLambda(self._generate_content)
            ),
            
            # Step 6: Content Enhancement - Embed Images, Add Compliance
            RunnablePassthrough.assign(
                enhanced_content=RunnableLambda(self._enhance_content)
            ),
            
            # Step 7: Final Output Formatting
            RunnableLambda(self._format_output)
        )
    
    def _analyze_content(self, input_data: Dict[str, Any]) -> ContentAnalysis:
        """Step 1: Analyze content for category and compliance requirements"""
        query = input_data.get("query", "").lower()
        
        # Detect gambling content
        gambling_matches = [kw for kw in self.gambling_keywords if kw in query]
        
        if gambling_matches:
            category = ContentCategory.GAMBLING
            compliance_required = True
            risk_level = "high"
            requires_age_verification = True
        else:
            category = ContentCategory.GENERAL
            compliance_required = False
            risk_level = "low"
            requires_age_verification = False
        
        return ContentAnalysis(
            category=category,
            compliance_required=compliance_required,
            detected_keywords=gambling_matches,
            risk_level=risk_level,
            requires_age_verification=requires_age_verification
        )
    
    def _gather_images(self, input_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Step 2a: Gather relevant images using DataForSEO"""
        try:
            # Import here to avoid circular imports
            from src.integrations.dataforseo_image_search import DataForSEOImageSearch
            
            query = input_data.get("query", "")
            analysis = input_data.get("analysis")
            
            # Create search queries based on content
            search_queries = self._generate_image_search_queries(query, analysis)
            
            image_service = DataForSEOImageSearch(
                supabase_client=self.supabase,
                config=self.config
            )
            
            all_images = []
            for search_query in search_queries[:3]:  # Limit to 3 searches
                try:
                    results = image_service.search_images(
                        query=search_query,
                        max_results=5,
                        filters={
                            "type": "photo",
                            "size": "medium",
                            "safe_search": "moderate"
                        }
                    )
                    
                    # Process and score images
                    for img in results.get("images", []):
                        img_data = {
                            "url": img.get("url"),
                            "alt_text": self._generate_alt_text(img, search_query),
                            "title": img.get("title", search_query),
                            "relevance_score": self._calculate_image_relevance(img, query),
                            "section_suggestion": self._suggest_image_section(img, query),
                            "width": img.get("width", 800),
                            "height": img.get("height", 600)
                        }
                        all_images.append(img_data)
                        
                except Exception as e:
                    logger.warning(f"Image search failed for '{search_query}': {e}")
                    continue
            
            # Sort by relevance and return top images
            all_images.sort(key=lambda x: x["relevance_score"], reverse=True)
            return all_images[:6]  # Maximum 6 images
            
        except Exception as e:
            logger.error(f"Image gathering failed: {e}")
            return []
    
    def _gather_authoritative_sources(self, input_data: Dict[str, Any]) -> List[Dict[str, Any]]:
        """Step 2b: Gather authoritative sources"""
        try:
            # Import contextual retrieval system
            from src.retrieval.contextual_retrieval import ContextualRetrievalSystem
            
            query = input_data.get("query", "")
            analysis = input_data.get("analysis")
            
            retrieval_system = ContextualRetrievalSystem(self.supabase)
            
            # Enhanced retrieval with source quality focus
            filters = {}
            if analysis.category == ContentCategory.GAMBLING:
                filters["source_type"] = ["official", "regulatory", "news"]
            
            docs = retrieval_system.retrieve(
                query=query,
                filters=filters,
                k=10,
                strategy="hybrid"
            )
            
            # Extract and validate sources
            sources = []
            for doc in docs:
                source_data = {
                    "url": doc.metadata.get("source_url"),
                    "title": doc.metadata.get("title"),
                    "domain": doc.metadata.get("domain"),
                    "authority_score": doc.metadata.get("authority_score", 0.5),
                    "content_snippet": doc.page_content[:200] + "...",
                    "source_type": doc.metadata.get("source_type", "article")
                }
                
                # Only include high-quality sources
                if source_data["authority_score"] >= 0.6:
                    sources.append(source_data)
            
            return sources[:8]  # Maximum 8 sources
            
        except Exception as e:
            logger.error(f"Source gathering failed: {e}")
            return []
    
    def _enhance_template(self, input_data: Dict[str, Any]) -> str:
        """Step 3: Dynamically enhance template based on analysis"""
        try:
            from src.templates.improved_template_manager import ImprovedTemplateManager
            
            query = input_data.get("query", "")
            analysis = input_data.get("analysis")
            resources = input_data.get("resources", {})
            
            template_manager = ImprovedTemplateManager()
            
            # Get base template
            base_template = template_manager.get_optimized_template(
                query_type="casino_review",  # Default for now
                expertise_level="intermediate"
            )
            
            # Enhance template based on analysis
            enhanced_sections = []
            
            # Add compliance section if needed
            if analysis.compliance_required:
                enhanced_sections.append("""
## Important Disclaimers
{compliance_notices}
""")
            
            # Add image placeholders
            if resources.get("images"):
                enhanced_sections.append("""
## Visual Overview
{image_content}
""")
            
            # Add authoritative sources section
            if resources.get("sources"):
                enhanced_sections.append("""
## References and Sources
{authoritative_sources}
""")
            
            # Combine with base template
            enhanced_template = base_template + "\n\n" + "\n\n".join(enhanced_sections)
            
            return enhanced_template
            
        except Exception as e:
            logger.error(f"Template enhancement failed: {e}")
            return input_data.get("query", "")
    
    def _enhanced_retrieval(self, input_data: Dict[str, Any]) -> List[Any]:
        """Step 4: Enhanced retrieval with contextual understanding"""
        try:
            from src.retrieval.contextual_retrieval import ContextualRetrievalSystem
            
            query = input_data.get("query", "")
            analysis = input_data.get("analysis")
            
            retrieval_system = ContextualRetrievalSystem(self.supabase)
            
            # Build filters based on analysis
            filters = {}
            if analysis.category == ContentCategory.GAMBLING:
                filters["content_type"] = ["review", "guide", "regulatory"]
            
            docs = retrieval_system.retrieve(
                query=query,
                filters=filters,
                k=15,
                strategy="contextual"
            )
            
            return docs
            
        except Exception as e:
            logger.error(f"Enhanced retrieval failed: {e}")
            return []
    
    def _generate_content(self, input_data: Dict[str, Any]) -> str:
        """Step 5: Generate content using enhanced template and context"""
        try:
            from src.chains.universal_rag_lcel import UniversalRAGChain
            
            query = input_data.get("query", "")
            enhanced_template = input_data.get("enhanced_template", "")
            retrieved_docs = input_data.get("retrieved_docs", [])
            
            # Create context from retrieved documents
            context = "\n\n".join([doc.page_content for doc in retrieved_docs[:10]])
            
            # Generate content using existing RAG chain
            rag_chain = UniversalRAGChain(self.supabase, self.config)
            
            content = rag_chain.invoke({
                "query": query,
                "context": context,
                "template": enhanced_template
            })
            
            return content
            
        except Exception as e:
            logger.error(f"Content generation failed: {e}")
            return f"Error generating content for: {input_data.get('query', 'Unknown query')}"
    
    def _enhance_content(self, input_data: Dict[str, Any]) -> EnhancedContent:
        """Step 6: Enhance content with images, compliance notices, and sources"""
        raw_content = input_data.get("raw_content", "")
        analysis = input_data.get("analysis")
        resources = input_data.get("resources", {})
        
        # Extract title
        title = self._extract_title(raw_content)
        
        # Embed images into content
        content_with_images = self._embed_images(raw_content, resources.get("images", []))
        
        # Add compliance notices
        compliance_notices = []
        if analysis.compliance_required:
            compliance_notices = self.compliance_notices.get(analysis.category.value, [])
            
            # Add compliance section to content
            compliance_section = "\n\n## Important Disclaimers\n\n"
            compliance_section += "\n\n".join([f"> {notice}" for notice in compliance_notices])
            content_with_images += compliance_section
        
        # Add authoritative sources
        sources = resources.get("sources", [])
        if sources:
            sources_section = "\n\n## References and Sources\n\n"
            for i, source in enumerate(sources[:5], 1):
                sources_section += f"{i}. [{source['title']}]({source['url']}) - {source['domain']}\n"
            content_with_images += sources_section
        
        return EnhancedContent(
            title=title,
            content=content_with_images,
            images=resources.get("images", []),
            sources=sources,
            compliance_notices=compliance_notices,
            metadata={
                "category": analysis.category.value,
                "compliance_required": analysis.compliance_required,
                "risk_level": analysis.risk_level,
                "generation_time": datetime.now().isoformat(),
                "image_count": len(resources.get("images", [])),
                "source_count": len(sources)
            }
        )
    
    def _format_output(self, input_data: Dict[str, Any]) -> Dict[str, Any]:
        """Step 7: Format final output"""
        enhanced_content = input_data.get("enhanced_content")
        
        return {
            "title": enhanced_content.title,
            "content": enhanced_content.content,
            "images": enhanced_content.images,
            "sources": enhanced_content.sources,
            "compliance_notices": enhanced_content.compliance_notices,
            "metadata": enhanced_content.metadata,
            "pipeline_version": "enhanced_v1.0.0",
            "processing_steps_completed": 7
        }
    
    # ============= HELPER METHODS =============
    
    def _generate_image_search_queries(self, query: str, analysis: ContentAnalysis) -> List[str]:
        """Generate relevant image search queries"""
        base_queries = [query]
        
        if analysis.category == ContentCategory.GAMBLING:
            # Add specific gambling-related image searches
            if "casino" in query.lower():
                base_queries.extend([
                    f"{query} homepage screenshot",
                    f"{query} mobile app interface",
                    f"{query} games lobby",
                    "live dealer casino games",
                    "casino slot machines interface"
                ])
        
        return base_queries
    
    def _generate_alt_text(self, image_data: Dict, search_query: str) -> str:
        """Generate descriptive alt text for images"""
        title = image_data.get("title", "")
        if title:
            return f"Image showing {title.lower()}"
        return f"Relevant image for {search_query}"
    
    def _calculate_image_relevance(self, image_data: Dict, query: str) -> float:
        """Calculate image relevance score"""
        score = 0.5  # Base score
        
        title = image_data.get("title", "").lower()
        query_words = query.lower().split()
        
        # Check title relevance
        matching_words = sum(1 for word in query_words if word in title)
        score += (matching_words / len(query_words)) * 0.3
        
        # Check image quality metrics
        width = image_data.get("width", 0)
        height = image_data.get("height", 0)
        
        if width >= 600 and height >= 400:
            score += 0.2
        
        return min(score, 1.0)
    
    def _suggest_image_section(self, image_data: Dict, query: str) -> str:
        """Suggest where to place the image in content"""
        title = image_data.get("title", "").lower()
        
        if "homepage" in title or "interface" in title:
            return "Overview"
        elif "game" in title or "slot" in title:
            return "Games"
        elif "mobile" in title or "app" in title:
            return "Mobile Experience"
        else:
            return "Introduction"
    
    def _embed_images(self, content: str, images: List[Dict[str, Any]]) -> str:
        """Embed images into content at appropriate locations"""
        if not images:
            return content
        
        lines = content.split('\n')
        enhanced_lines = []
        images_used = 0
        
        for i, line in enumerate(lines):
            enhanced_lines.append(line)
            
            # Insert image after section headers
            if line.startswith('##') and images_used < len(images):
                image = images[images_used]
                
                img_html = f"""
<div class="content-image">
    <img src="{image['url']}" 
         alt="{image['alt_text']}" 
         title="{image['title']}"
         width="{image.get('width', 800)}" 
         height="{image.get('height', 600)}"
         loading="lazy" />
    <p class="image-caption"><em>{image['title']}</em></p>
</div>
"""
                enhanced_lines.append(img_html)
                images_used += 1
        
        return '\n'.join(enhanced_lines)
    
    def _extract_title(self, content: str) -> str:
        """Extract title from content"""
        lines = content.split('\n')
        for line in lines:
            if line.startswith('# '):
                return line[2:].strip()
            elif line.startswith('## '):
                return line[3:].strip()
        
        # Fallback: use first non-empty line
        for line in lines:
            if line.strip():
                return line.strip()[:100]
        
        return "Generated Content"

# ============= FACTORY FUNCTION =============

def create_enhanced_rag_pipeline(supabase_client, config: Dict[str, Any]) -> EnhancedUniversalRAGPipeline:
    """Factory function to create enhanced RAG pipeline"""
    return EnhancedUniversalRAGPipeline(supabase_client, config) 